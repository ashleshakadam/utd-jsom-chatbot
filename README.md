# ğŸ¤– JSOM Chatbot â€“ Ask Me Anything

A local AI-powered chatbot designed to answer questions about the Naveen Jindal School of Management (JSOM) at The University of Texas at Dallas. Built using LangChain, FAISS, Streamlit, and Mistral (via Ollama).

---

## ğŸš€ Features

- ğŸ” Vector search using FAISS
- ğŸ“„ Local embeddings via HuggingFace transformers
- ğŸ’¬ Natural language QA with Mistral LLM via Ollama
- ğŸŒ Streamlit-powered web app
- ğŸ§  Context-aware document querying

---

## ğŸ“ Project Structure

jsom_chatbot/
â”‚
â”œâ”€â”€ app.py                  # Streamlit frontend
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_vectorstore.py  # Script to embed docs + build FAISS index
â”œâ”€â”€ data/
â”‚   â””â”€â”€ admissions.txt       # Raw scraped JSOM content
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ faiss_index          # Vector store (auto-generated)
â”œâ”€â”€ .env                    # Your environment variables (e.g., API keys)
â””â”€â”€ requirements.txt        # Dependencies

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/ashleshakadam/utd-jsom-chatbot.git
cd jsom-chatbot

2. Create & Activate a Virtual Environment

python3 -m venv venv
source venv/bin/activate

3. Install Requirements

pip install -r requirements.txt

4. Setup Ollama (Mistral)

Install Ollama:

brew install ollama
ollama serve

Then pull the model:

ollama run mistral

5. Build the Vectorstore

python scripts/build_vectorstore.py

6. Run the Chatbot

streamlit run app.py

Then visit ğŸ‘‰ http://localhost:8501

â¸»

âš™ï¸ Environment Variables

Create a .env file in your project root with the following:

# Not needed with Ollama but helpful for optional OpenAI fallback
OPENAI_API_KEY=sk-xxxxx...



â¸»

ğŸ“š Acknowledgments
	â€¢	LangChain
	â€¢	FAISS
	â€¢	Sentence Transformers
	â€¢	Ollama
	â€¢	Streamlit

â¸»

ğŸ’¬ Questions or Contributions?

Feel free to open an issue or submit a PR. Letâ€™s make academic info more accessible!

â¸»

ğŸ§  Author

Built with â¤ï¸ by Ashlesha Kadam

---
